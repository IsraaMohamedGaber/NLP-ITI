{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To work with Word2Vec, especially comparing CBOW (Continuous Bag of Words) and Skip-Gram architectures, we typically train a model using the Gensim library. However, the model you're referring to — 'glove-wiki-gigaword-100' — is pre-trained using the GloVe algorithm, not Word2Vec. GloVe is another word embedding algorithm developed by Stanford, and it doesn't distinguish between CBOW and Skip-Gram."
      ],
      "metadata": {
        "id": "4v4APyiWUzWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Feature                 | CBOW (Continuous Bag of Words)                         | Skip-Gram                                            |\n",
        "| ----------------------- | ------------------------------------------------------ | ---------------------------------------------------- |\n",
        "| **Goal**                | Predict the target word from surrounding context words | Predict surrounding context words from a target word |\n",
        "| **Training speed**      | Faster (more efficient on large data)                  | Slower (more computations)                           |\n",
        "| **Performs better for** | Frequent words                                         | Rare words                                           |\n",
        "| **Use case**            | General NLP tasks with sufficient data                 | Capturing representations of infrequent words better |\n"
      ],
      "metadata": {
        "id": "bAA0DzG4Ungq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install gensim\n",
        ""
      ],
      "metadata": {
        "id": "mJb_i_cnVdbK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "Ou-JyIrjVAWr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List available models\n",
        "print(\"Available models:\")\n",
        "print(api.info()['models'].keys())\n",
        "model = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P6xLlwtbQm4",
        "outputId": "457b681f-d83b-4dd5-f80f-a6beab2d1fa7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available models:\n",
            "dict_keys(['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cbow VS SkipGram"
      ],
      "metadata": {
        "id": "MjdoLh7Qcha2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cbow_predict(context_words, model, topn=5):\n",
        "    \"\"\"\n",
        "        Get vector for each context word and average them\n",
        "    \"\"\"\n",
        "    context_vectors = []\n",
        "    for word in context_words:\n",
        "        if word in model:\n",
        "            context_vectors.append(model[word])\n",
        "        else:\n",
        "            print(f\"'{word}' not in vocabulary.\")\n",
        "\n",
        "    if not context_vectors:\n",
        "        return []\n",
        "\n",
        "    # Average the vectors to get the context representation\n",
        "    avg_vector = np.mean(context_vectors, axis=0)\n",
        "    # Use most_similar to find top-n closest words to the context vector\n",
        "    similar_words = model.similar_by_vector(avg_vector, topn=topn)\n",
        "\n",
        "    return similar_words\n"
      ],
      "metadata": {
        "id": "jq77-BC4bQ-r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = [\"king\", \"man\"]\n",
        "predicted_words = cbow_predict(context, model)\n",
        "print(\"Predicted words:\", predicted_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfMYVyeRbbkF",
        "outputId": "b148aebb-1401-47ee-c51e-2960806c9680"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted words: [('king', 0.8817193508148193), ('man', 0.8566084504127502), ('father', 0.8132981061935425), ('brother', 0.8037790656089783), ('son', 0.7959659695625305)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def skipgram_predict(target_word, model, topn=5):\n",
        "    \"\"\"\n",
        "    Predict context words given a target word using the Skip-gram approach.\n",
        "    \"\"\"\n",
        "    if target_word not in model:\n",
        "        print(f\"'{target_word}' not in vocabulary.\")\n",
        "        return []\n",
        "\n",
        "    # Get most similar words to the target word\n",
        "    similar_words = model.most_similar(target_word, topn=topn)\n",
        "\n",
        "    return similar_words\n"
      ],
      "metadata": {
        "id": "c2y-Xevibg40"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"king\"\n",
        "predicted_context = skipgram_predict(target, model)\n",
        "print(\"Predicted context words:\", predicted_context)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlT0O43Xbz7Z",
        "outputId": "f03cfee1-22a2-4a66-81ec-410793f6f097"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted context words: [('prince', 0.7682328820228577), ('queen', 0.7507690787315369), ('son', 0.7020888328552246), ('brother', 0.6985775232315063), ('monarch', 0.6977890729904175)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "21quKmySb2Gu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}